{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caro aluno, acabamos de conhecer mais 2 tipos de redes neurais, agora para consolidar este conhecimento nada melhor do que o aspecto prático. Vamos desenvolver uma rede neural do tipo convolucional e vamos utilizar o tensorflow para tornar nossa vida mais fácil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos desenvolver um programa capaz de reconhecer, isto é predizer o nome de frutas. Neste projeto vamos trabalhar com  81 classes de frutas e para ajudar nossas tarefas de treinamento e execução vamos usar o Tensorflow. Vamos nessa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Começamos importando as bibliotecas necessárias para visualização dos dados\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from sklearn.datasets import load_files\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('fruits-360/Training/Apple Red 1/101_100.jpg')\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos dar uma olhada nestas frutas, primeiro uma maçã e agora uma cereja.\n",
    "img = mpimg.imread('fruits-360/Training/Cherry Wax Black/101_100.jpg')\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados que temos são imagens, vamos separar estes dados em bases separadas de \"Treino\" e \"Teste\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "train_categories = []\n",
    "train_samples = []\n",
    "for i in os.listdir(\"fruits-360/Training/\"):\n",
    "    train_categories.append(i)\n",
    "    train_samples.append(len(os.listdir(\"fruits-360/Training/\"+ i)))\n",
    "\n",
    "test_categories = []\n",
    "test_samples = []\n",
    "for i in os.listdir(\"fruits-360/Test/\"):\n",
    "    test_categories.append(i)\n",
    "    test_samples.append(len(os.listdir(\"fruits-360/Test/\"+ i)))\n",
    "\n",
    "    \n",
    "print(\"Count of Fruits in Training set:\", sum(train_samples))\n",
    "print(\"Count of Fruits in Set set:\", sum(test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição das Frutas com Contagem no dataset de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_size = plt.rcParams[\"figure.figsize\"]\n",
    "figure_size[0] = 40\n",
    "figure_size[1] = 20\n",
    "plt.rcParams[\"figure.figsize\"] = figure_size\n",
    "index = np.arange(len(train_categories))\n",
    "plt.bar(index, train_samples)\n",
    "plt.xlabel('Frutas', fontsize=25)\n",
    "plt.ylabel('Contagem das Frutas', fontsize=25)\n",
    "plt.xticks(index, train_categories, fontsize=15, rotation=90)\n",
    "plt.title('Distribuição das Frutas com Contagem no dataset de Treinamento', fontsize=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição das Frutas com Contagem no dataset de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2 = np.arange(len(test_categories))\n",
    "plt.bar(index2, test_samples)\n",
    "plt.xlabel('Frutas', fontsize=25)\n",
    "plt.ylabel('Contagem de Frutas', fontsize=25)\n",
    "plt.xticks(index2, test_categories, fontsize=15, rotation=90)\n",
    "plt.title('Distribuição das Frutas com Contagem no dataset de Teste', fontsize=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hora de carregar todos os dados de treinamento e teste\n",
    " - Inputs/Imagens de Treinamento em x_train e as categorias/rótulos y_train\n",
    " - Inputs/Imagens de Teste em x_test e as categorias/rótulos y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = 'fruits-360/Training/'\n",
    "test_dir = 'fruits-360/Test/'\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    data_loading = load_files(data_path)\n",
    "    files_add = np.array(data_loading['filenames'])\n",
    "    targets_fruits = np.array(data_loading['target'])\n",
    "    target_labels_fruits = np.array(data_loading['target_names'])\n",
    "    return files_add,targets_fruits,target_labels_fruits\n",
    "    \n",
    "x_train, y_train,target_labels = load_dataset(train_dir)\n",
    "x_test, y_test,_ = load_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes de Frutas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81 classes/rótulos porque nosso dataset é composto de 81 tipos de frutas. Como sabemos que estamos usando 81 classes/rótulos, vamos criar um vetor de 81 valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = len(np.unique(y_train))\n",
    "no_of_classes\n",
    "y_train = np_utils.to_categorical(y_train,no_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test,no_of_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vamos sub-dividir os dados de teste em dados de validação. Os dados de validação serão usados durante o treinamento do modelo para verificar o desempenho durante o treinamento e os dados de teste serão usados após o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,x_valid = x_test[7000:],x_test[:7000]\n",
    "y_test,y_vaild = y_test[7000:],y_test[:7000]\n",
    "print('Vaildation X : ',x_valid.shape)\n",
    "print('Vaildation y :',y_vaild.shape)\n",
    "print('Test X : ',x_test.shape)\n",
    "print('Test y : ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até agora, os dados são apenas imagens. Precisamos convertê-los em forma de arrays para  treinamento e teste do modelo, porque ele só entende os dados numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array_form(files):\n",
    "    images_array=[]\n",
    "    for file in files:\n",
    "        images_array.append(img_to_array(load_img(file)))\n",
    "    return images_array\n",
    "\n",
    "x_train = np.array(convert_image_to_array_form(x_train))\n",
    "print('Training set shape : ',x_train.shape)\n",
    "\n",
    "x_valid = np.array(convert_image_to_array_form(x_valid))\n",
    "print('Validation set shape : ',x_valid.shape)\n",
    "\n",
    "x_test = np.array(convert_image_to_array_form(x_test))\n",
    "print('Test set shape : ',x_test.shape)\n",
    "\n",
    "print('1st training image shape ',x_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature Scalling de 0-255 para 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de converter as imagens em arrays, vimos anteriormente que os intervalos pixels vão de 0 a 255. Estamos re-escalar estes pixels de 0-255 para uma escala de 0-1. Mas porque fazer isto? Fazendo isso, podemos reduzir o tempo de treinamento. Porque também podemos alimentar os mesmos recursos. Observe que quando o modelo for treinado, demorará mais para calcular os valores de 0-255 do que de 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_valid = x_valid.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Implementação do modelo pelo Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com tudo pronto, agora podemos focar na topologia do nosso modelo. Vamos fazer um 'drill-down' de cada camada, mas observe depois no código como fica simples e limpa a estruturação do modelo pelo Tensorflow. Vamos lá:\n",
    "- Step 01: Usamos aqui a base 'Sequencial', trata-se de uma restrição do para treinamento e tunnning dos parâmetros em dados de imagem. \n",
    "- Step 02: Implementaremos uma camada de Convolução aqui, do tipo Conv2D, onde filtros são applicados a imagem original para reduzir o número de features. Depois um kernel é aplicado para transformar um input de 16 filtros produzindo um tensor de outputs. \n",
    "- Step 03: Aqui temos uma função de ativação para decidir o que será aproveitado ou descartado.\n",
    "- Step 04: Depois temos uma camada de pooling, a função Maxpooling que chamamos aqui calcula o valor máximo em cada patch do mapa de features aplicado no Step 02. Ele pega o valor dos vetores de entrada e prepara o vetor para as próximas camadas.\n",
    "- Step 05: Usamos aqui uma camada de Dropout, mas porque fazer isso em uma rede neural? O descarte de alguns neurônios não utilizados, ou utilizados incorretamente é comum para evitar o overfitting do nosso modelo.\n",
    "- Step 06: Depois convertemos o array 2D em um array 1D com todas as features.\n",
    "- Step 07: Por fim, adicionamos uma camada densa para reduzir os outputs pegando os inputs da camada anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensorflow_based_model():\n",
    "    model = Sequential() #step 1\n",
    "    model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same')) #step2\n",
    "    model.add(Activation('relu'))  # step3\n",
    "    model.add(MaxPooling2D(pool_size=2)) # step4\n",
    "    model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same')) #repeatindo o step 2 e o step3 mas com mais filtros de 32\n",
    "    model.add(MaxPooling2D(pool_size=2)) #repeatindo o 4 \n",
    "    model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same')) #repeatindo o step 2 e o step3 mas com mais filtros de 64\n",
    "    model.add(MaxPooling2D(pool_size=2)) #repeatindo o 4 again\n",
    "    model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same')) #repeatindo o step 2 e o step3 mas com mais filtros de 64\n",
    "    model.add(MaxPooling2D(pool_size=2)) #repeatindo o step 4 \n",
    "    model.add(Dropout(0.3)) # step5\n",
    "    model.add(Flatten()) #step 6\n",
    "    model.add(Dense(150)) #step 7\n",
    "    model.add(Activation('relu')) # setp 3\n",
    "    model.add(Dropout(0.4)) # step 5\n",
    "    model.add(Dense(81,activation = 'softmax')) # step3 e step7. Só que desta vez, estamos usando uma função de ativação como um softmax\n",
    "    return model #função retornando o valor quando chamada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compilação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primeiro chamamos o Modelo.\n",
    "- Como estamos usando 81 classes vamos parametrizar nosso loss como \"categorical_crossentropy\"\n",
    "- A função de otimização (optimizer) é utilizada para alterar os recursos da rede neural, como a taxa de aprendizado (como o modelo aprende com os features) para reduzir as perdas. Portanto, a taxa de aprendizagem da rede neural para reduzir as perdas é definida por esta otimizador.\n",
    "- Vamos adicionar também métricas de acurácia porque vamos calcular a porcentagem de predições corretas sobre todas as predições no dataset de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tensorflow_based_model() \n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Vamos alimentar o modelo com os dados de treinamento e validação com os seguintes parâmetros:\n",
    "    - Batch Size = 32: Para que o modelo pegue 80 imagens a cada iteração de treinamento. O Batch size é um termo usado em Machine Learning e refere-se ao número de exemplos de treinamento utilizados em uma iteração.\n",
    "    - Epochs = 30: Para que o modelo seja treinado 30 vezes. Epoch é outro termo comum em Machine Learning e india o número de passagens em todo o dataset de treinamento.\n",
    "- Podemos escolher batch_size e epochs como quisermos, então a boa prática é definir alguns valores e treinar o modelo se o modelo não der os bons resultados, podemos alterá-lo e depois tentar novamente para o treinamento do modelo. Podemos repetir esse processo muitas vezes até não obtermos os bons resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,\n",
    "        batch_size = 32,\n",
    "        epochs=30,\n",
    "        validation_data=(x_valid, y_vaild),\n",
    "        verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia do modelo nos dataset de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos definir acurácia como o número correto de imagens reconhecidas de todas as imagens.\n",
    "- Por exemplo, se o modelo treinado reconhece 90 imagens corretas e erra em 10 em um total de 100 imagens a acurácia é de 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = model.evaluate(x_test, y_test) \n",
    "print('\\n', 'Test accuracy:', acc_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização da predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Vamos usar nosso modelo treinado para predizer algumas amostras nos dados de teste.\n",
    "- DENTRO dos parênteses temos o VERDADEIRO nome das frutas.\n",
    "- FORA dos parênteses temos a PREDICAO do nome das frutas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(predictions[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}